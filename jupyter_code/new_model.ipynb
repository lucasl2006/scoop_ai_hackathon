{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9502f2bf-9351-4187-9d8b-fbd46c639d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def compute_features(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    First column = rebound label.\n",
    "    Remaining columns = candle data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Keep everything except the first column (label)\n",
    "    feature_df = df.iloc[:, 1:]\n",
    "\n",
    "    # Convert to float32 numpy array\n",
    "    features = feature_df.values.astype(np.float32)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb066172-da65-4d51-a566-393ac60cfdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import root_mean_squared_error \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class CandlePatternPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim = 64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),  # Predict next price movement\n",
    "            nn.Sigmoid()       # convert confidence to a probability\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "# Example:\n",
    "# input_dim = features.shape[1]\n",
    "# model = CandlePatternPredictor(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3d32167-80d7-4974-8d24-a33cb310a09c",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3_13\\envs\\ai_env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: (slice(None, None, None), 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mInvalidIndexError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 89\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# 3 Train if run as script\u001b[39;00m\n\u001b[32m     88\u001b[39m csv_path = \u001b[33m\"\u001b[39m\u001b[33m../data/scoop_bulls_test.csv\u001b[39m\u001b[33m\"\u001b[39m     \u001b[38;5;66;03m# You can replace this with your path\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(csv_path, batch_size, lr, epochs)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_model\u001b[39m(csv_path, batch_size = \u001b[32m32\u001b[39m, lr = \u001b[32m1e-3\u001b[39m, epochs = \u001b[32m20\u001b[39m):\n\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     X, y = \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# Convert to tensors\u001b[39;00m\n\u001b[32m     35\u001b[39m     X_tensor = torch.tensor(X).float()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mload_data\u001b[39m\u001b[34m(csv_path)\u001b[39m\n\u001b[32m     20\u001b[39m X = compute_features(df)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Target labels (0 or 1)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m y = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m.values.astype(np.float32)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3_13\\envs\\ai_env\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3_13\\envs\\ai_env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3818\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m   3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[31mInvalidIndexError\u001b[39m: (slice(None, None, None), 0)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# 1 Load your CSV with the rebound labels\n",
    "def load_data(csv_path):\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Check rebound label\n",
    "    #if \"rebounded\" not in df.columns:\n",
    "    #    raise ValueError(\"CSV must contain a 'rebounded' column with 0/1 labels.\")\n",
    "\n",
    "    #shuffles rows\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Compute feature matrix\n",
    "    X = compute_features(df)\n",
    "\n",
    "    # Target labels (0 or 1)\n",
    "    y = df[:,0].values.astype(np.float32)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# 2 Training loop\n",
    "def train_model(csv_path, batch_size = 32, lr = 1e-3, epochs = 20):\n",
    "\n",
    "    # Load data\n",
    "    X, y = load_data(csv_path)\n",
    "\n",
    "    # Convert to tensors\n",
    "    X_tensor = torch.tensor(X).float()\n",
    "    y_tensor = torch.tensor(y).float().unsqueeze(1)  # shape: [N, 1]\n",
    "\n",
    "    # Dataset + loader\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Create model\n",
    "    input_dim = X.shape[1]\n",
    "    model = CandlePatternPredictor(input_dim)\n",
    "\n",
    "    # Loss + optimizer\n",
    "    criterion = nn.BCELoss()  # binary cross entropy for 0/1 predictions\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training Loop\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch_X, batch_y in loader:\n",
    "\n",
    "            # Forward\n",
    "            preds = model(batch_X)\n",
    "            loss = criterion(preds, batch_y)\n",
    "\n",
    "            # Backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Compute accuracy\n",
    "            predicted_classes = (preds >= 0.5).float()\n",
    "            correct += (predicted_classes == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "\n",
    "        accuracy = correct / total\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {epoch_loss:.4f} | Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "    # Save model weights\n",
    "    save_path = \"model/trained_candle_model.pth\"\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    print(f\"\\nTraining complete! Model saved to: {save_path}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# 3 Train if run as script\n",
    "csv_path = \"../data/scoop_bulls_test.csv\"     # You can replace this with your path\n",
    "train_model(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728317c8-cd17-4b39-b6c6-866a4b770846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
